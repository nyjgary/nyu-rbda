[yjn214@login-1-1 hwk2-mapreduce]$ hadoop jar /opt/cloudera/parcels/CDH/lib/hadoop-mapreduce/hadoop-streaming.jar -D mapreduce.job.reduces=1 -files hdfs://dumbo/user/yjn214/wordcount-mr/mapper.py,hdfs://dumbo/user/yjn214/wordcount-mr/reducer.py -mapper "python mapper.py" -reducer "python reducer.py" -input /user/yjn214/wordcount-mr/input_data.txt -output /user/yjn214/wordcount-mr/output
packageJobJar: [] [/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/jars/hadoop-streaming-2.6.0-cdh5.15.2.jar] /tmp/streamjob4620496667622901050.jar tmpDir=null
19/06/09 23:37:13 INFO mapred.FileInputFormat: Total input paths to process : 1
19/06/09 23:37:13 INFO mapreduce.JobSubmitter: number of splits:2
19/06/09 23:37:13 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1551899815467_53344
19/06/09 23:37:13 INFO impl.YarnClientImpl: Submitted application application_1551899815467_53344
19/06/09 23:37:13 INFO mapreduce.Job: The url to track the job: http://babar.es.its.nyu.edu:8088/proxy/application_1551899815467_53344/
19/06/09 23:37:13 INFO mapreduce.Job: Running job: job_1551899815467_53344
19/06/09 23:37:18 INFO mapreduce.Job: Job job_1551899815467_53344 running in uber mode : false
19/06/09 23:37:18 INFO mapreduce.Job:  map 0% reduce 0%
19/06/09 23:37:23 INFO mapreduce.Job:  map 100% reduce 0%
19/06/09 23:37:28 INFO mapreduce.Job:  map 100% reduce 100%
19/06/09 23:37:28 INFO mapreduce.Job: Job job_1551899815467_53344 completed successfully
19/06/09 23:37:28 INFO mapreduce.Job: Counters: 49
	File System Counters
		FILE: Number of bytes read=90
		FILE: Number of bytes written=474669
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=640
		HDFS: Number of bytes written=35
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=18952
		Total time spent by all reduces in occupied slots (ms)=13866
		Total time spent by all map tasks (ms)=4738
		Total time spent by all reduce tasks (ms)=2311
		Total vcore-milliseconds taken by all map tasks=4738
		Total vcore-milliseconds taken by all reduce tasks=2311
		Total megabyte-milliseconds taken by all map tasks=19406848
		Total megabyte-milliseconds taken by all reduce tasks=14198784
	Map-Reduce Framework
		Map input records=3
		Map output records=12
		Map output bytes=105
		Map output materialized bytes=139
		Input split bytes=208
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=139
		Reduce input records=12
		Reduce output records=4
		Spilled Records=24
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=588
		CPU time spent (ms)=11790
		Physical memory (bytes) snapshot=2566737920
		Virtual memory (bytes) snapshot=11209449472
		Total committed heap usage (bytes)=4411883520
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters
		Bytes Read=432
	File Output Format Counters
		Bytes Written=35
19/06/09 23:37:28 INFO streaming.StreamJob: Output directory: /user/yjn214/wordcount-mr/output
[yjn214@login-1-1 hwk2-mapreduce]$ hdfs dfs -ls wordcount-mr/output
Found 2 items
-rw-r-----+  3 yjn214 users          0 2019-06-09 23:37 wordcount-mr/output/_SUCCESS
-rw-r-----+  3 yjn214 users         35 2019-06-09 23:37 wordcount-mr/output/part-00000
[yjn214@login-1-1 hwk2-mapreduce]$ hdfs dfs -cat wordcount-mr/output/part-00000
Chicago	1
Dec	2
hackathon	2
Java	0